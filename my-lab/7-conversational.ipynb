{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9ccd50aa414398a7c0f55605678758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30f7c971e2c4209bc6901d8ffa26302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8f2fbb24a14663a358c3376a04126f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fa5c21b2ee4b1eb3ab21b3b3f0fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59b746c7b5c4313b399fc4833447f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d3c3497f234080978e88367e9e4238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8d12fb7074419ca52a0bbf7ee90ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather like today?\n",
      "Bot: It's sunny and 75 degrees.\n",
      "User: Will it rain tomorrow?\n",
      "Bot: There is a 20% chance of rain tomorrow.\n",
      "User: How about the temperature tomorrow?\n",
      "Bot: It's around 70 degrees.\n",
      "User: What's the weather like today?\n",
      "Bot: It's sunny and 75 degrees.\n",
      "User: Will it rain tomorrow?\n",
      "Bot: There is a 20% chance of rain tomorrow.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"gpt2\"  # You can choose another model as well\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to build prompt from conversation history\n",
    "def build_prompt(history, new_question):\n",
    "    prompt = \"\"\n",
    "    for turn in history:\n",
    "        prompt += f\"User: {turn['user']}\\nBot: {turn['bot']}\\n\"\n",
    "    prompt += f\"User: {new_question}\\nBot:\"\n",
    "    return prompt\n",
    "\n",
    "# Example conversation history\n",
    "history = [\n",
    "    {\"user\": \"What's the weather like today?\", \"bot\": \"It's sunny and 75 degrees.\"},\n",
    "    {\"user\": \"Will it rain tomorrow?\", \"bot\": \"There is a 20% chance of rain tomorrow.\"}\n",
    "]\n",
    "\n",
    "# New question from the user\n",
    "new_question = \"How about the temperature tomorrow?\"\n",
    "\n",
    "# Build the prompt with the conversation history\n",
    "prompt = build_prompt(history, new_question)\n",
    "\n",
    "# Tokenize the input and convert it to a tensor\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "# Generate a response from the model\n",
    "output = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# Decode the model's output to get the response text\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
